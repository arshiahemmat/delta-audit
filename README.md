# Delta-Audit ðŸ”€ðŸ§­ðŸ“Š

*A lightweight Î”-Attribution suite for auditing model updates (Aâ†’B) with behavioural linkage and robustness checks.*

[![CI](https://github.com/arshiahemmat/delta-audit/workflows/CI/badge.svg)](https://github.com/arshiahemmat/delta-audit/actions)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)

## Overview

Delta-Audit provides a comprehensive suite of Î”-Attribution metrics to understand how model explanations change when models are updated. It implements behavioural alignment, conservation error, and stability measures to audit model updates across different algorithms and datasets.

![Overview Figure](delta_attr_run/results/figures/fig0_overview.png)

## Quickstart

```bash
# Install in a virtual environment
python3 -m venv .venv && source .venv/bin/activate
pip install -e . && pip install -r requirements.txt

# Run a quick demonstration (5 minutes)
delta-audit quickstart

# Run the full benchmark (45 experiments)
delta-audit run --config configs/full_benchmark.yaml

# Generate figures from results
delta-audit figures --summary delta_attr_run/results/_summary --out figures/

# Run sanity checks
delta-audit check
```

## Repository Structure

```
delta-audit/
â”œâ”€â”€ src/delta_audit/          # Main package
â”‚   â”œâ”€â”€ metrics.py            # Î”-Attribution metrics implementation
â”‚   â”œâ”€â”€ explainers.py         # Attribution computation methods
â”‚   â”œâ”€â”€ runners.py            # Training and evaluation pipelines
â”‚   â”œâ”€â”€ plotting.py           # Figure generation utilities
â”‚   â”œâ”€â”€ io.py                 # Data loading and saving
â”‚   â””â”€â”€ cli.py                # Command-line interface
â”œâ”€â”€ configs/                  # Configuration files
â”‚   â”œâ”€â”€ quickstart.yaml       # Quick demonstration config
â”‚   â””â”€â”€ full_benchmark.yaml   # Full benchmark config
â”œâ”€â”€ delta_attr_run/           # Original experiment structure
â”‚   â”œâ”€â”€ code/                 # Original scripts (for reproducibility)
â”‚   â””â”€â”€ results/              # Results and figures
â”œâ”€â”€ paper/                    # Research paper
â”‚   â””â”€â”€ ICCKE_delta.pdf       # NOT AVAILABLE NOW!
â”œâ”€â”€ docs/                     # Documentation website
â””â”€â”€ .github/                  # GitHub workflows and templates
```

## Reproducing the Paper

To reproduce all results and figures from the paper:

```bash
# 1. Install dependencies
pip install -e . && pip install -r requirements.txt

# 2. Run the full benchmark (reproduces all 45 experiments)
delta-audit run --config configs/full_benchmark.yaml

# 3. Generate all figures
delta-audit figures --summary delta_attr_run/results/_summary --out delta_attr_run/results/figures/

# 4. Check results
delta-audit check
```

The results will be saved in `delta_attr_run/results/` with the same structure as in the paper.

## Î”-Attribution Metrics

Delta-Audit implements the following metrics:

- **BAC (Behavioral Alignment Coefficient)**: Correlation between attribution change magnitude and output change magnitude
- **DCE (Differential Conservation Error)**: Difference between sum of attribution changes and actual output change
- **Î” Magnitude L1**: L1 norm of attribution differences
- **Î” TopK10**: Fraction of total magnitude captured by top-10 features
- **Î” Entropy**: Entropy of normalized attribution differences
- **Rank Overlap @10**: Overlap between top-10 features of two attribution sets
- **JSD (Jensen-Shannon Divergence)**: Distributional shift between attribution sets
- **COÎ”F**: Conservation of relevant features for fixes and regressions
- **Î” Stability**: Robustness to input perturbations

## Supported Algorithms

- **Logistic Regression**: Different regularization strengths and solvers
- **Support Vector Classification**: Different kernels and parameters
- **Random Forest**: Different ensemble sizes and feature selection
- **Gradient Boosting**: Different learning rates and tree depths
- **K-Nearest Neighbors**: Different neighbor counts and distance metrics

## Supported Datasets

- **Breast Cancer**: Binary classification (569 samples, 30 features)
- **Wine**: Multi-class classification (178 samples, 13 features)
- **Digits**: Multi-class classification (1797 samples, 64 features)

## Documentation

See the [documentation website](https://arshiahemmat.github.io/delta-audit) for detailed guides:

- [Getting Started](docs/getting-started.md)
- [Concepts](docs/concepts.md)
- [Metrics](docs/metrics.md)
- [API Reference](docs/api.md)
- [CLI Reference](docs/cli.md)
- [Benchmarks](docs/benchmarks.md)

## Citation

If you use Delta-Audit in your research, please cite (Will be available soon!):

```bibtex
@article{hemmat2025delta,
  title={Delta-Audit: Explaining What Changes When Models Change},
  author={Hemmat, Arshia},
  journal={arXiv preprint},
  year={2025}
}
```

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

Thanks to the open-source community for the excellent tools that made this project possible, particularly scikit-learn, matplotlib, and pandas. 
